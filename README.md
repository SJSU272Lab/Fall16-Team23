# Fall16-Team23

#Project Name

##Abstract
Problem:


Natural Language channel such as words,script or body language such as gestures(hand or head),facial expression and lip motion are the main means of interaction for human beings.These languages are easy to understand for many  but may be difficult for  people having speech and hearing disability.And therefore a need of special language for these disabled people is needed. But normal people face difficulty in understanding these sign languages.


Solution:


We are going to implement an user interface which takes signs as input from the disabled people either by capturing the images or by sensors.These inputs are interpreted using existing algorithms and processed as symbols of a language from our database.We are going to take American Sign Language as reference.The user will be able to understand with the help of these symbols.And we name our application as Trans-Sense.

##User Stories

![alt tag](https://github.com/SJSU272Lab/Fall16-Team23/blob/master/FinalProject/1.png)

##Architecture Diagram

![alt tag](https://github.com/SJSU272Lab/Fall16-Team23/blob/master/FinalProject/flowchart.png)
